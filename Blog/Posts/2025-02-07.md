# The first post of february and a short post.
Apparently this week hasn't been that exiting.

## Lets get this website out of the way with to begin with
Although i have to be careful, i have a lot of files yet to be committed. It's not like i can't talk about those files, those files are WIP, i just don't want to say features which are out when they are technically not out yet.
![A picture of the uncommitted files i have from running the command `git status`. Contains files in many folders.](Blog/Assets/2025-02-07/Screenshot_20250207_194811.png)

So, lets start with the commits that have actually been published.

### Local time improvements.
The local time in markdown is a very useful function as mentioned in a [previous blog post](https://dragmine149.github.io/Blog?blog=2025-01-31). However, back then it had two major issues. The first being negative time, and the second being the location.
Now however, the function has been extracted into it's own file: [marked_local_time.js](https://github.com/dragmine149/dragmine149.github.io/blob/main/Blog/marked_local_time.js). (And of cause, the negative time was fixed).

The negative time was an easy fix, just a check to see if it was negative and then absolute it but change the output slightly. Interestingly, and slightly confusing. Negative time is actually how long until said time.

After writing this section, there is one more feature i want to add. The ability to hover over a specific time to actually see the time it is, instead of `in X years` or whatever.
![Image from discord showing what happens when you hover over a time element](Blog/Assets/2025-02-07/Screenshot_20250207_200332.png)

I'll work on that somepoint after i finished the files i've got half finished.

### Image fixes.
For those who read the aoc blog sometime after day 21 and before this fix, you'll know what i mean. Although, it might have also occurred for more people...

Basically (and for those who don't know), when images get too long width wise, the whole post / `div` would be able to scroll horizontally as well. Which well, can cause some unwanted side effects. If scrolled, a whole bunch of whitespace would appear just
making the whole thing look bad.

And the way to solve this? Another file, this time [marked_improved_image.js](https://github.com/dragmine149/dragmine149.github.io/blob/main/Blog/marked_improved_image.js). Unlike the previous file, this one is designed more as a personal use than to be shared
but it'll be shared anyway.

This file, just has a custom render to take any `<img>` and put them inside `<div>`, then with this style:
```css
#blog_content div.img {
  width: 100%;
  overflow: auto;
}
```
the images can still scroll horizontally, without moving the whole blog post at once.

### So, about these marked files.
Currently, they are bundled in my website repo. However, as `marked.js` has many other extensions, as i add more files and features, i might move them to their own repo and just submodule them in to this website repo.
Even so, you can still use them if they are in this repo or not. I'm not looking for credit with these files as they are really simple stuff.

### Second to last fix, code blog copying.
So, even though you could select the whole codeblock. Due to the code highlighter, you couldn't actually copy the code. Just a bunch of symbols. I only found this one out when i tried to copy the [marked_local_time] and got this:
![A bunch of characters with a lot of red errors due to zed not understand them](Blog/Assets/2025-02-07/Screenshot_20250203_105301.png)

So now there is this listener:
```js
// Have to expand the copy function because otherwise it won't copy everything.
window.addEventListener('copy', function (event) {
  let selection = window.getSelection();
  if (selection.focusNode.nodeName === 'CODE') {
    event.clipboardData.setData("text/plain", selection.focusNode.innerText);
    event.preventDefault();
  }
});
```

I didn't want to do this by adding another event listener, i wanted to actually select the code. But that was going to prove tricky, so time to listen to every single copy event... (is there a better way?)

Basically put, when you have the code block selected and you copy it, the whole thing would get copied. The only downside here, is that it doesn't work without javascript, but then at that point half of this site doesn't so it kinda doesn't matter much anyway.

### The big feature... I have a new spell checker! And it's local too.
The old one i'm was using is [check-spelling](https://github.com/check-spelling/check-spelling), which is decent, it does the job. But required a lot of changes to be made to the `except` and `patterns` file due to the ton of invalid cases.
The main example, is a lot of japanese related spelling "mistakes" kept appearing due to always using the japanese name in the MAL url.

Now however, i'm using [typos](https://github.com/crate-ci/typos). Well more specifically, this version: [zed-typos](https://github.com/BaptisteRoseau/zed-typos).

There are two major benefits:
1. `Typos` run locally, i've been correcting spelling of this post as i've been writing it because of that.
  I might in the future set up the github action version, to make sure i don't miss anything, but for now i'll stick to the local version
2. `Typos` can detect things way better. From what i gathered with `check-spelling`, they seemed to be focused more on code bases, which would make sense of all the errors. However, not only does typos work on code bases, it also works on other files.
  `check-spelling` failed all the time on things like, links, languages, comments, etc. whereas `typos` not only knows what is a link and what isn't a link, but also works with languages.

So, long story short. Good bye old spell checker, you will not be missed. (It has a use somewhere, just not in my case).

(Also, i've gone ahead and fixed the spelling mistakes in the last blogs, so enjoy. With this new system their shouldn't be any, unless it's well something like the `colour` and `color` issue...)

### These work in progress features...
I've been hinting at these, so might as well spill. DO note, at time of writing these are still work in progress. The features will be released sometime this month though.

- Settings which actually save thanks to `localStorage`
- Improved page loader (once again, although with proper branch support this time)
- Modules (so that i don't have to load the whole blog page, just to render a markdown post)

There is still a long way to go on some of them, hence why they haven't been committed yet. But those are some of the next planned features to come.

### Wait, wait, wait. This section isn't over yet...
I have once again (last minute decision), expanded [tools](https://github.com/dragmine149/dragmine149.github.io/blob/main/tools/src/main.rs), now with an `rss` feed.

Do note, i actually don't know much about rss feeds and just kinda threw it together, the extension that is. However, i should have followed the specification set out here: [https://www.rssboard.org/rss-specification#syndic8](https://www.rssboard.org/rss-specification#syndic8).

In a way, it's another way of viewing [list.json](https://dragmine149.github.io/Blog/list.json), although a format which is more widely used and can be subscribed to apparently, so enjoy.

## One website down, now lets see if i can remember what i did with the pi...
Whener i document stuff, i kinda prefer to get it FULLY completed before attempting to document it. I know in some cases i should be documenting as i go, but in other cases i would kinda prefer to just get it over with and worry about all the paperwork later.
So lets see, setting wordpress up on the pi...

### First step, setting up wordpress.
Easy, following [this tutorial](https://pimylifeup.com/raspberry-pi-wordpress/), nice and simple got it setup with not much issue.

### Second step, sorting out linux permissions
This took me down a rabbit hole...

In order for wordpress to edit the files, the files needed ownership (or group) of `www-data`, even after adding the user account `wp` to the group, `sudo` was still required.
I could have just used `sudo` whenever, but i didn't want to as i want to have control over these files and not leave everything up to root.

Eventually, came across this [serverfault post](https://serverfault.com/questions/6895/whats-the-best-way-of-handling-permissions-for-apache-2s-user-www-data-in-var), which after following and then modifying into this script
```sh
# permissions.zsh

#!/bin/zsh
sudo chown -R www-data:www-pub /var/www
sudo chmod 2775 /var/www
sudo find /var/www -type d -exec chmod 2775 {} +
sudo find /var/www -type f -exec chmod 0664 {} +
sudo chmod +x /var/www/html/permissions.zsh
```
allowed both the `wp` user and wordpress to edit the same files.
The main difference between this script, and the serverfault post is how the ownership is defined. The serverfault post did `www-pub:www-pub`, which didn't give wordpress access. Hence `www-data:www-pub` was need to give wordpress access and also our group access.

### Third step, sorting out the website
The pi is home to not only this website, but also to my gitea instance. Although they are technically on different ports, i still wanted it to be that anyone can go to either if they just went to the pi ip.

Hence like i've done plenty a time, a folder for wordpress, and a folder for a redirect to gitea.

### Forth step, figure out why apache2 isn't working...
Whilst trying to get wordpress to restore from a backup (more on that later), there was these issues about the `rest-api` not being accessible. Of cause, like always the error that is given is really not helpful at all.
Turns out, it was an issue with `apache2` not reading from the `.htaccess` file, which was another rabbit hole.

Even following posts like [this stackoverflow](https://stackoverflow.com/questions/18740419/how-to-set-allowoverride-all#22526144), still didn't make it work straight away.
At one point i found a post, but can't remember the link (i did most of this in private browsing, so no history either). I finally came to the fact that the command `sudo a2enmod rewrite` needed to be run.

### Fifth step, get out of here you imposter.
This was actually done during the forth step, but well.

Sometime during messing around with `apache2`, `apache2` would fail to run. Eventually i found the reason was due to `lighttpd.service`, which had started at some time. Normally this wouldn't be an issue, which service was hosting the website.
But by default at least, `apache2` will show a file system if the folder contains no `index.html` file, which is what i wanted.

### Sixth stsp, time to important from one website to another.
Which is kinda impossible.

The full export, is just over 2MB which is the limit of the wp file uploader (for some reason).

The backup system that was in place, is actually behind a paid tier (i mean, fine, but comeon, you won't allow me to load the backup at least? although tbh it probably wouldn't have done much)

Copying the files one by one takes forever, and even then. There isn't a good way to import data easily. If you try to copy over the databases, you'll just get linked back to the old website instead of the new one.

Eventually however, everything was sorted out just. Not in the best way, but in a way which allows me to be able to work on the website.

### Final seventh step, automatic uploads via gitea.
Although gitea supports github workflows, gitea still pioritises it's own workflow folder `.gitea/workflows` over `.github/workflows` and vis-versa for github.

This means, i can have different workflows on gitea than github which is really useful. The workflows don't cause the over workflow to give an error due to it being on a different server.

The workflow itself was copied over from the old stuff with some changes, instead of uploading to github as an artifact, it would instead upload to the pi wordpress folder (via `sftp`) straight away.

The artifact upload to github, is only so that wordpress can detect the file and steal it from github. Github never actually uploads to wordpress which is annoying as it eats up all of my artifact limit. Hence this whole new setup.

Thankfully however, uploading to the pi consisted of just one command
```sh
./sshpass -p 'wp' sftp -o "StrictHostKeyChecking no" wp@127.0.0.1:/var/www/html/ldg/wp-content/themes <<<$'put -R GuildWebsite/'
```

`sshpass` is a tool to pass any password directly to `ssh` or `sftp`. I'ved used it for automating uploads via `sftp` all the time when i couldn't do it via `ssh` keys.

`-o "StrictHostKeyChecking no"` is required to keep skipping the `Are you sure you want to add this host check`. As we are uploading to the pi itself, we are the host so we don't really care. We have to skip it due to the command being run in a docker container
as that is just how actions are run. Thanks to this [superuser post](https://superuser.com/questions/19563/how-do-i-skip-the-known-host-question-the-first-time-i-connect-to-a-machine-vi), for the answer.

### Finally, everything is setup.
And i can work without issue. No more having to worry about github limits on the free teir, well as much at least.

## The worpress on pi did get me wondering...
Is there a better CLI tool for `sftp`?

I mean sure, i could just use a GUI tool like [filezilla](https://filezilla-project.org/), but there is something nice about doing it via the command line and `sftp`.

The problems i have with `sftp` are:
- Does not support alias / local commands.
    Makes sense, it doesn't mount it. But then doing stuff like `l` to quickly list instead of `ls` and it failing is annoying.
- Small files takes forever to copy with slow server.
    Whilst download the `wp-content` from `wordpress.com`, it took a good couple of minutes. Because of all the individual small files. When i was uploading it to the pi however, it went zoom.
    If possible, i want parallel downloads / uploads of directories. They are only small files, it shouldn't be that much of an issue right?

I did try searching, but to no avial. I have thought of making something (i'm calling) `rsftp`, which is a CLI tool made in rust to be a better sftp, but for now thats on hold. I don't use sftp that much, and i've currently got to focus on website stuff so...

## I thought i didn't have a lot to talk about
Yet i've gotten into nearly 200 lines...

I mean yay, a lot of stuff to talk about. But also it's a lot of stuff.

## Right, one last thing.
I actually completed this... *searches steam*... Just over a week ago.

I completed (100%) my first `visual novel (VN)`. Which was an interesting experience to say the least.

The VN i chose to be my first was [riddle joker](https://store.steampowered.com/app/1277930/Riddle_Joker/) as for why i chose that visual novel... Well due to this [beatmap on osu!](https://osu.ppy.sh/beatmapsets/1519872#osu/3223086).
<sub><sup>When i play osu!, i download a lot of beatmaps. I've gotten quite a collection of those which are the openings to visual novels. As such, this one was just one which i enjoyed listening to and playing the beatmap, hence why i chose it.</sup></sub>

Overally, i quite enjoyed riddle joker. It did take me ~45 hours to get through over 3 months. But i'm happy i enjoyed it and brought it. Do i recommend it? YES! Well mostly.

During each of the character routes, there is at least one **long** scene of them kissing, which i skipped through most of the time. And there is at least one scene which **doesn't show it** but does heavly talk on about the MC and whoever route having sex with each other.

Other than those secens, the story is fine and fun. I'll try not to spoil it too much here. The BGM is also enjoyable to listen to, to the point where i've found [this playlist](https://www.youtube.com/playlist?list=PLX3jEqVZs62VXyxhFzYtCthyiPSu0xhRe), which i'll
probably have on as background music in some of my streams in the near future.

Normally, i don't like rewatching, or rereading the same things. Because well, i've done it, i know what happens. It's kinda worthless redoing that one at least unless it was extremely special or has been a very long (couple of years) time.
The second playthrough i tried to read the main story again, but semi gave up half way through. And just skipped to the individual routes after that playthrough.

The route order i did was:
- Nanami
- Mayu
- Normal
- Chisaki
- Hazuki
- Ayase

After completing Nanmi's and Mayu's route, i ended up following this [steam walkthrough](https://steamcommunity.com/sharedfiles/filedetails/?id=2323376164), and one of the comments on that walkthrough.

The most fun routes (imo), were `Nanami` (first route bias but her route is still fun), and `Mayu` (unique ability usage is all i'll say). The rest of the routes were interesting but still kinda of meh. Also very surprising in some cases (looking at you Hazuki)

The final thing i did, was make this picture. Surprisingly there are a lot of assets and possible choices for the game, even though we kept seeing the same assets used over and over again.
![A picture of the whole group: Nanami; Mayu; Chisaki; Hazuki; Ayaze; Kyouhei. Standing in front of the school at dusk](Blog/Assets/2025-02-07/riddle_joker_20250128_010345.png)

Like everything, it is always sad once it is over. But the memories and experience made along the way is defenitally worth it (and the set of new and interesting ideas it gave).

I already have my next visual novel brought and downloaded. I'm kinda taking a break from VN for a while just so i don't get too bored of them. (They are long and take quite a lot of effort sometimes, unlike anime). Once i complete that one however, i will also write about it.

## Alright this very long special blog has now come to a close.
New record, 230 lines... And 4 images. Here i was thinking i didn't have much to write about erm... 3 hours ago...? (started writing at: <t:1738957591:T> (`19:36`), currently <t:1738967520:T> (`22:32`).
I suppose having no-one but a void all week makes some of these extremely long.

Right, time to watch todays set of anime and take a rest..., lets leave the other website issues and work in progress projects til the weekend.
